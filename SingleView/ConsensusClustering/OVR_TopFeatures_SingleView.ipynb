{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad2aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from mvlearn.cluster import MultiviewKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "from ConsensusClusteringMultiView import ConsensusCluster\n",
    "import scipy.stats as sps\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pathlib import Path\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7989ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_F_stat(data):\n",
    "    SSB = (\n",
    "        ((data.groupby(\"cluster\").mean() - data.drop(\"cluster\", 1).mean()) ** 2).T\n",
    "        * data.groupby(\"cluster\").size().values\n",
    "    ).sum(1)\n",
    "\n",
    "    SSW = []\n",
    "    assert len(data[\"cluster\"].unique()) == 2\n",
    "    for k in sorted(data[\"cluster\"].unique()):\n",
    "        cluster = data[data[\"cluster\"] == k].drop(\"cluster\", 1)\n",
    "        diff = (cluster - data.groupby(\"cluster\").mean().loc[k]) ** 2\n",
    "        SSW.append(diff)\n",
    "    SSW = pd.concat(SSW).sum()\n",
    "    coef = (len(data) - len(data[\"cluster\"].unique())) / (\n",
    "        len(data[\"cluster\"].unique()) - 1\n",
    "    )\n",
    "    F_stat = (coef * (SSB / SSW)).sort_values(ascending=False)\n",
    "    return F_stat\n",
    "\n",
    "\n",
    "def get_ovr_F_stat(data, num_var):\n",
    "    F_stat_true = cal_F_stat(data)\n",
    "    all_F_stat = []\n",
    "    n_test = 19 * num_var\n",
    "    for i in tqdm(range(n_test)):\n",
    "        data_run = data.copy()\n",
    "        rs = np.random.RandomState(i)\n",
    "        random_assignment = data_run[\"cluster\"].tolist()\n",
    "        rs.shuffle(random_assignment)\n",
    "        data_run[\"cluster\"] = random_assignment\n",
    "        F_stat = cal_F_stat(data_run)\n",
    "        all_F_stat.append(F_stat)\n",
    "\n",
    "    all_F_stat = pd.concat(all_F_stat, 1)\n",
    "    all_F_stat.columns = [\"random {}\".format(i + 1) for i in range(all_F_stat.shape[1])]\n",
    "    all_F_stat[\"true\"] = F_stat_true\n",
    "    return all_F_stat\n",
    "\n",
    "def plot_top(data, target_var, save_path, name):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    target_cluster = np.unique(data[\"cluster\"])\n",
    "    for i, var in enumerate(target_var):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        for k in target_cluster:\n",
    "            cluster = data[data[\"cluster\"] == k]\n",
    "            plt.hist(\n",
    "                cluster[var],\n",
    "                bins=25,\n",
    "                alpha=0.5,\n",
    "                density=True,\n",
    "                histtype=\"stepfilled\",\n",
    "                label=\"cluster {}, size {}\".format(k, len(cluster)),\n",
    "            )\n",
    "        plt.legend()\n",
    "        plt.title(var, fontsize=15)\n",
    "    plt.suptitle(name, fontsize=25)\n",
    "   \n",
    "    plt.savefig(\n",
    "        \"{}/{}.png\".format(save_path, name), dpi=300,\n",
    "    )\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f97c6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "score_path = \"{}/Clustering_silhouette/\".format(data_path)\n",
    "cdf_path = \"{}/CDF plots/\".format(data_path)\n",
    "tsne_path = \"{}/TSNEplots/\".format(data_path)\n",
    "KCC_path = \"{}/KCC/\".format(data_path)\n",
    "f_stat_path = '{}/F_stat_OVR/'.format(data_path)\n",
    "top_feature_plot_path = '{}/Top_features_OVR/'.format(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bccf2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_view = pd.read_csv(\"data/PhysioViewStandardized.csv\", index_col=0)\n",
    "physio_view_original = pd.read_csv(\"data/PhysioViewNormalImputed.csv\", index_col=0)\n",
    "physio_view_original = physio_view_original[physio_view.columns]\n",
    "binary_vars = pd.read_csv(\"{}/ClinicalBinary.csv\".format(data_path), index_col=0)\n",
    "\n",
    "proteome_view = pd.read_csv(\"data/ProteomeViewMICEimputed.csv\", index_col=0)\n",
    "npx = pd.read_csv(\"../olinks/20191053_Giannoni_NPX.csv\")\n",
    "npx.set_index(\"Panel\", inplace=True)\n",
    "\n",
    "uniport = {}\n",
    "for k, p in enumerate(npx.columns):\n",
    "    uniport[p] = npx.iloc[:, k][\"Uniprot ID\"]\n",
    "uniprot_col = []\n",
    "for col in proteome_view.columns:\n",
    "    uniprot_col.append(uniport[col])\n",
    "\n",
    "proteome_view.columns = uniprot_col\n",
    "continous_vars = pd.concat([physio_view_original, proteome_view], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b42f48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_continous_vars = continous_vars.shape[1]\n",
    "nb_binary_vars = binary_vars.shape[1]\n",
    "total_vars = nb_continous_vars + nb_binary_vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b286a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [\"clinical\", 4, \"ConsensusKMeans\"],\n",
    "    [\"contextual\", 5, \"ConsensusKMeans\"],\n",
    "    [\"physio\", 3, \"DBSCAN\"],\n",
    "    [\"proteome\", 3, \"ConsensusKMeans\"],\n",
    "    [\"proteome\", 4, \"ConsensusKMeans\"],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff201e6a",
   "metadata": {},
   "source": [
    "# OVR Fisher exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(configs)):\n",
    "    view, KCC_space, method = configs[i]\n",
    "\n",
    "    assignment = pd.read_csv(\n",
    "        \"{}/{}_{}_view_KCC_{}_assignments.csv\".format(\n",
    "            score_path, method, view, KCC_space\n",
    "        ),\n",
    "        index_col=0,\n",
    "    )\n",
    "    print(assignment.head())\n",
    "    if method == \"DBSCAN\":\n",
    "        assignment[\"assignment\"] = assignment[\"assignment\"] + 1\n",
    "        assignment = assignment[assignment[\"assignment\"] != 0]\n",
    "    assignment[\"assignment\"] = assignment[\"assignment\"].astype(int)\n",
    "    \n",
    "    data = binary_vars.copy()\n",
    "    data[\"cluster\"] = assignment[\"assignment\"]\n",
    "    data = data[data[\"cluster\"].notnull()]\n",
    "    \n",
    "    num_cluster = len(data[\"cluster\"].unique())\n",
    "    all_clusters = sorted(data[\"cluster\"].unique())\n",
    "\n",
    "    for i in all_clusters:\n",
    "        i = int(i)\n",
    "        data_ovr = data.copy()\n",
    "        data_ovr.loc[data[data['cluster'] != i].index, 'cluster'] = i + 1\n",
    "        save_name = \"{}_{}_KCC_{}_FisherExact_cluster_{}vsR.csv\".format(\n",
    "                    method, view, KCC_space, i\n",
    "                )\n",
    "        \n",
    "        for col in binary_vars.columns:\n",
    "            try:\n",
    "                contingency_table = pd.crosstab(\n",
    "                    data_ovr[col], data_ovr[\"cluster\"]\n",
    "                )\n",
    "                p_val = stats.fisher_exact(contingency_table)[1]\n",
    "                all_p_val.loc[col] = p_val\n",
    "            except:\n",
    "                pass\n",
    "        all_p_val.to_csv(\"{}/{}\".format(f_stat_path, save_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46954fe4",
   "metadata": {},
   "source": [
    "# OVR F-stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████▌                                   | 4978/9120 [06:36<05:50, 11.81it/s]"
     ]
    }
   ],
   "source": [
    "for i in range(len(configs)):\n",
    "    view, KCC_space, method = configs[i]\n",
    "    assignment = pd.read_csv(\n",
    "        \"{}/{}_{}_view_KCC_{}_assignments.csv\".format(\n",
    "            score_path, method, view, KCC_space\n",
    "        ),\n",
    "        index_col=0,\n",
    "    )\n",
    "    if method == \"DBSCAN\":\n",
    "        assignment[\"assignment\"] = assignment[\"assignment\"] + 1\n",
    "        assignment = assignment[assignment[\"assignment\"] != 0]\n",
    "\n",
    "    data = continous_vars.copy()\n",
    "    data[\"cluster\"] = assignment[\"assignment\"]\n",
    "    data = data[data[\"cluster\"] != 0]\n",
    "    num_cluster = len(data[\"cluster\"].unique())\n",
    "    all_clusters = sorted(data[\"cluster\"].unique())\n",
    "    \n",
    "    for i in all_clusters:\n",
    "        data_ovr = data.copy()\n",
    "        data_ovr.loc[data[data['cluster'] != i].index, 'cluster'] = i + 1\n",
    "        save_name = \"{}_{}_KCC_{}_F_stat_cluster_{}vsR.csv\".format(\n",
    "                        method, view, KCC_space, i\n",
    "                    )\n",
    "        all_F_stat = get_ovr_F_stat(data_ovr, total_vars)\n",
    "        F_stat_true = all_F_stat[\"true\"]\n",
    "        F_stat_true_pvalue = (\n",
    "            all_F_stat.rank(axis=1, ascending=False)[\"true\"]\n",
    "            / all_F_stat.shape[1]\n",
    "        )\n",
    "        F_stat_true = pd.concat([F_stat_true, F_stat_true_pvalue], 1)\n",
    "        F_stat_true.columns = [\"F_stat\", \"p-value\"]\n",
    "\n",
    "        F_stat_true.to_csv(\"{}/{}\".format(f_stat_path, save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9121ec",
   "metadata": {},
   "source": [
    "# plot top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(configs)):\n",
    "    view, KCC_space, method = configs[i]\n",
    "\n",
    "    assignment = pd.read_csv(\n",
    "        \"{}/{}_{}_view_KCC_{}_assignments.csv\".format(\n",
    "            score_path, method, view, KCC_space\n",
    "        ),\n",
    "        index_col=0,\n",
    "    )\n",
    "    if method == \"DBSCAN\":\n",
    "        assignment[\"assignment\"] = assignment[\"assignment\"] + 1\n",
    "        assignment = assignment[assignment[\"assignment\"] != 0]\n",
    "    assignment[\"assignment\"] = assignment[\"assignment\"].astype(int)\n",
    "    data = all_features.copy()\n",
    "    data[\"cluster\"] = assignment[\"assignment\"]\n",
    "    data = data[data[\"cluster\"].notnull()]\n",
    "    print(data.shape)\n",
    "    num_cluster = len(data[\"cluster\"].unique())\n",
    "    all_clusters = sorted(data[\"cluster\"].unique())\n",
    "\n",
    "    for i in all_clusters:\n",
    "        for j in all_clusters:\n",
    "            if j > i:\n",
    "                i, j = int(i), int(j)\n",
    "                cluster_pw = data[(data[\"cluster\"] == i) | (data[\"cluster\"] == j)]\n",
    "                fstat_name = \"{}_{}_KCC_{}_F_stat_cluster_{}vs{}.csv\".format(\n",
    "                    method, view, KCC_space, i, j\n",
    "                )\n",
    "                F_stat = pd.read_csv(\n",
    "                    \"{}/{}\".format(f_stat_path, fstat_name), index_col=0\n",
    "                )\n",
    "\n",
    "                fisher_name = \"{}_{}_KCC_{}_FisherExact_cluster_{}vs{}.csv\".format(\n",
    "                    method, view, KCC_space, i, j\n",
    "                )\n",
    "                Fisher = pd.read_csv(\n",
    "                    \"{}/{}\".format(f_stat_path, fisher_name), index_col=0\n",
    "                )\n",
    "                Fisher.columns = [\"p-value\"]\n",
    "                Fisher[\"F_stat\"] = np.nan\n",
    "\n",
    "                F_stat = F_stat[F_stat[\"p-value\"] < 0.05]\n",
    "                Fisher = Fisher[Fisher[\"p-value\"] < 0.05 /total_vars]\n",
    "                stats = pd.concat([F_stat, Fisher])\n",
    "                stats = (\n",
    "                    stats.sort_values(\"p-value\")\n",
    "                    .sort_values(\"F_stat\", ascending=False)\n",
    "                    .iloc[:10]\n",
    "                )\n",
    "                fig_name = \"{}_{}_KCC_{}_TopFeatures_cluster_{}vs{}\".format(\n",
    "                    method, view, KCC_space, i, j\n",
    "                )\n",
    "                plot_top(\n",
    "                    cluster_pw, stats.index.tolist(), top_feature_plot_path, fig_name\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8cc97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
